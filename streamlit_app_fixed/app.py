"""Streamlit entrypoint for the Suri Q&AI application."""

import os
from io import StringIO
from typing import Dict, Iterable, List
import pandas as pd
import streamlit as st

from core.ai_engine import generate_ai_response, summarize_by_keywords, summarize_long_csv
from core.ai_utils import clean_text_with_ai
from core.database import ensure_db, insert_csv_to_db, load_csv_files, load_csv_from_db, list_tables
from core.hybrid_search import hybrid_search
from core.rag import build_databases
from profiles_page import profiles_page


DATA_DIR = "data"
RAW_DOCS_DIR = os.path.join(DATA_DIR, "raw_docs")
VECTOR_DB_DIR = os.path.join(DATA_DIR, "vector_db")
PARSED_CSV_PATH = os.path.join(DATA_DIR, "parsed_docs.csv")

# === ìˆ˜ì•”ëª…ë¦¬ ì „ìš© íƒœê·¸ ===
RULE_CATEGORIES = ["ê¶ìœ„", "í—ˆíˆ¬", "ëŒ€ìƒ", "ë¬˜ê³ ", "ìƒí˜¸ì‘ìš©"]
PRIORITY_LEVELS = ["1. êµ¬ì¡° ê²°ì •", "2. íŠ¹ìˆ˜ êµ¬ì¡°", "3. í—ˆíˆ¬/ì…ë¬˜", "4. ì¼ë°˜ë¡ "]
CASE_FOCUS_TOPICS = ["ì§ì—…/ì‚¬íšŒìš´", "ê°€ì¡±/ìœ¡ì¹œ", "ì¬ë¬¼ìš´", "ê±´ê°•/í•™ì—…ìš´"]


def configure_app():
    st.set_page_config(page_title="Suri Q&AI", layout="wide")
    st.title("ğŸ“Š Suri Q&AI")
    ensure_directories([DATA_DIR, RAW_DOCS_DIR, VECTOR_DB_DIR])
    ensure_db()


def ensure_directories(paths: Iterable[str]):
    for path in paths:
        os.makedirs(path, exist_ok=True)


# ----------------------------
# ë¬¸ì„œ ì—…ë¡œë“œ
# ----------------------------
def render_upload_section():
    st.header("ğŸ“‘ ë¬¸ì„œ ì—…ë¡œë“œ ë° íŒŒì‹±")

    parser_mode = st.radio("íŒŒì„œ ëª¨ë“œ ì„ íƒ", ["ê·œì¹™ ê¸°ë°˜", "AI ë³´ì¡°", "Hybrid"], horizontal=True)
    uploaded_files = st.file_uploader("txt/md íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "md"], accept_multiple_files=True)

    if not uploaded_files:
        return

    for uploaded_file in uploaded_files:
        file_content = uploaded_file.read().decode("utf-8")
        st.subheader(f"ğŸ“„ {uploaded_file.name}")
        st.text_area("íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", file_content[:1000], height=200)

        if not st.button(f"íŒŒì‹± ì‹¤í–‰: {uploaded_file.name}"):
            continue

        save_path = os.path.join(RAW_DOCS_DIR, uploaded_file.name)
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(file_content)

        parsed_df = parse_document_by_mode(file_content, parser_mode)
        if parsed_df.empty:
            st.warning("âš ï¸ íŒŒì‹± ê²°ê³¼ ì—†ìŒ")
            continue

        st.success("âœ… íŒŒì‹± ì™„ë£Œ, AI êµì • ì¤‘...")
        raw_text = parsed_df.to_csv(index=False, encoding="utf-8-sig")
        cleaned_df = clean_dataframe_with_ai(raw_text, parsed_df)

        st.success("âœ… AI êµì • ì™„ë£Œ, ìˆ˜ì • ê°€ëŠ¥")
        edited_df = st.data_editor(cleaned_df, num_rows="dynamic", use_container_width=True)

        if st.button(f"{uploaded_file.name} ì €ì¥", key=f"save_{uploaded_file.name}"):
            combined = merge_with_existing_csv(edited_df)
            combined.to_csv(PARSED_CSV_PATH, index=False, encoding="utf-8-sig")
            insert_csv_to_db(combined, "parsed_docs")
            st.success(f"ğŸ“¦ DB ì €ì¥ ì™„ë£Œ (ì´ {len(combined)}í–‰)")


def parse_document_by_mode(file_content: str, parser_mode: str) -> pd.DataFrame:
    rows: List[Dict[str, str]] = []
    if "ê·œì¹™" in parser_mode:
        from core.parsing import parse_document
        cases, rules, concepts = parse_document(file_content)
    elif "AI" in parser_mode:
        from core.parse_document_ml import parse_document_ml
        cases, rules, concepts = parse_document_ml(file_content)
    else:
        from core.parse_document_hybrid import parse_document_hybrid
        cases, rules, concepts = parse_document_hybrid(file_content)

    for c in cases:
        rows.append({"type": "case", "id": c["id"], "content": c.get("detail", "")})
    for r in rules:
        rows.append({"type": "rule", "id": r["id"], "content": r.get("desc", "")})
    for c in concepts:
        rows.append({"type": "concept", "id": c["id"], "content": c.get("desc", "")})
    return pd.DataFrame(rows)


def clean_dataframe_with_ai(raw_text, fallback_df):
    cleaned_text = clean_text_with_ai(raw_text)
    try:
        return pd.read_csv(StringIO(cleaned_text))
    except:
        return fallback_df


def merge_with_existing_csv(edited_df):
    if os.path.exists(PARSED_CSV_PATH):
        old_df = pd.read_csv(PARSED_CSV_PATH)
        combined = pd.concat([old_df, edited_df], ignore_index=True)
        combined = combined.drop_duplicates(subset=["type", "id", "content"])
        return combined
    return edited_df


# ----------------------------
# DB ë¯¸ë¦¬ë³´ê¸°
# ----------------------------
def render_db_preview():
    st.header("ğŸ“¦ DB ë¯¸ë¦¬ë³´ê¸°")
    if st.button("DB ë¶ˆëŸ¬ì˜¤ê¸°"):
        db_df = load_csv_from_db("parsed_docs")
        if db_df.empty:
            st.warning("âš ï¸ DB ë¹„ì–´ìˆìŒ")
        else:
            st.dataframe(db_df, use_container_width=True)


# ----------------------------
# ìš”ì•½
# ----------------------------
def render_summary():
    st.header("ğŸ“ CSV ìš”ì•½")
    if st.button("CSV ì „ì²´ ìš”ì•½"):
        csv_text = build_combined_csv_text()
        if not csv_text:
            return st.warning("ë°ì´í„° ì—†ìŒ")
        summary, parts = summarize_long_csv(csv_text)
        st.text_area("ìš”ì•½ ê²°ê³¼", summary, height=300)


def build_combined_csv_text():
    csv_dfs = load_csv_files(DATA_DIR)
    if not csv_dfs:
        return ""
    combined = pd.concat(list(csv_dfs.values()), ignore_index=True)
    return combined.to_csv(index=False, encoding="utf-8-sig")


# ----------------------------
# ìƒë‹´
# ----------------------------
def render_ai_consultation():
    st.header("ğŸ’¬ ìƒë‹´")
    query = st.text_input("ì§ˆë¬¸ ì…ë ¥")
    if st.button("AI ì‘ë‹µ"):
        if not query.strip():
            return st.warning("ì§ˆë¬¸ ì—†ìŒ")
        docs = hybrid_search(query, db_dir=VECTOR_DB_DIR, k=5)
        context = "\n\n".join([doc.page_content for doc in docs])
        answer = generate_ai_response(f"{query}\n\nì°¸ê³ ìë£Œ:\n{context}")
        st.markdown(answer)


# ----------------------------
# DB ê´€ë¦¬
# ----------------------------
def render_db_manage():
    st.header("ğŸ—‚ï¸ DB ê´€ë¦¬")
    if st.button("í…Œì´ë¸” ëª©ë¡"):
        st.write(list_tables())


# ----------------------------
# Main
# ----------------------------
def main():
    configure_app()
    choice = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", ["ë¬¸ì„œ ê´€ë¦¬", "DB ë¯¸ë¦¬ë³´ê¸°", "ìš”ì•½", "ìƒë‹´", "í”„ë¡œí•„"])
    if choice == "ë¬¸ì„œ ê´€ë¦¬":
        render_upload_section()
    elif choice == "DB ë¯¸ë¦¬ë³´ê¸°":
        render_db_preview()
    elif choice == "ìš”ì•½":
        render_summary()
    elif choice == "ìƒë‹´":
        render_ai_consultation()
    elif choice == "í”„ë¡œí•„":
        profiles_page()
    else:
        render_db_manage()


if __name__ == "__main__":
    main()

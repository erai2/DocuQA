# core/ai_engine.py
import os
from typing import Union

import pandas as pd
from openai import OpenAI

from core.rag import search_vector_db
from core.settings_manager import load_settings


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_ai_response(user_query, db_name="default_db"):
    """ë²¡í„°DB ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    docs = search_vector_db(user_query, db_name=db_name, k=3)
    context = "\n\n".join(
        [f"[ì¶œì²˜:{d.metadata.get('source', 'unknown')}] {d.page_content}" for d in docs]
    )

    prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ì£¼ëª…ë¦¬ ì „ë¬¸ê°€ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ ì•„ë˜ ë¬¸ì„œ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•´ ë‹µë³€í•˜ì„¸ìš”.

    === ì»¨í…ìŠ¤íŠ¸ ===
    {context}

    === ì§ˆë¬¸ ===
    {user_query}
    """

    response = client.chat.completions.create(
        model=model,
        temperature=temperature,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì£¼ëª…ë¦¬ ì „ë¬¸ê°€ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
    )

    answer = response.choices[0].message.content
    if docs:
        sources = ", ".join(set([d.metadata.get("source", "unknown") for d in docs]))
        answer += f"\n\nğŸ“Œ ì°¸ê³ ìë£Œ: {sources}"

    return answer


def _build_preview_from_source(data_source: Union[str, pd.DataFrame]) -> str:
    """ìš”ì•½ì— ì‚¬ìš©í•  ë°ì´í„° ìƒ˜í”Œ ë¬¸ìì—´ ìƒì„±"""

    if isinstance(data_source, pd.DataFrame):
        if data_source.empty:
            return ""
        return data_source.head(20).to_string()

    if isinstance(data_source, str):
        potential_path = data_source.strip()
        if os.path.isfile(potential_path):
            try:
                df = pd.read_csv(potential_path)
            except Exception:
                # ê²½ë¡œë¡œ ì²˜ë¦¬í–ˆìœ¼ë‚˜ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ í™œìš©
                return data_source
            if df.empty:
                return ""
            return df.head(20).to_string()
        # íŒŒì¼ ê²½ë¡œê°€ ì•„ë‹ˆë©´ ë°ì´í„° ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
        return data_source

    raise TypeError("data_sourceëŠ” ë¬¸ìì—´ ê²½ë¡œ/í…ìŠ¤íŠ¸ ë˜ëŠ” pandas.DataFrame ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")


def summarize_with_ai(data_source: Union[str, pd.DataFrame], save_path: str = None):
    """ë°ì´í„° ì†ŒìŠ¤ë¥¼ ìš”ì•½í•˜ì—¬ ë°˜í™˜"""

    preview = _build_preview_from_source(data_source)
    if not preview.strip():
        return "ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”."

    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")

    prompt = f"""
    ë‹¤ìŒì€ ë°ì´í„°ì˜ ìƒ˜í”Œì…ë‹ˆë‹¤:

    {preview}

    ì´ ë°ì´í„°ì˜ ì£¼ìš” íŒ¨í„´ê³¼ ìš”ì•½ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    """

    response = client.chat.completions.create(
        model=model,
        temperature=0.3,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ë° ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
    )

    summary = response.choices[0].message.content

    if save_path:
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(summary)

    return summary

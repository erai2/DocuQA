import os
import openai
import streamlit as st
from core.rag import search_vector_db
from core.settings_manager import load_settings

# ğŸ”‘ secrets.tomlì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
openai.api_key = st.secrets["OPENAI_API_KEY"]


def generate_ai_response(user_query: str):
    """ë¬¸ì„œ ê¸°ë°˜ Q&A"""
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    docs = search_vector_db(user_query, db_dir=st.secrets["VECTOR_DB_DIR"], k=3)
    context = "\n\n".join(
        [f"[ì¶œì²˜:{d.metadata.get('source','unknown')}] {d.page_content}" for d in docs]
    )

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ìˆ˜ì•”ëª…ë¦¬ DocuQA ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": f"ì§ˆë¬¸: {user_query}\n\nì°¸ê³ ìë£Œ:\n{context}"},
        ],
        temperature=temperature,
    )
    return response["choices"][0]["message"]["content"]


def ask_csv_ai(user_query: str):
    """CSV ë°ì´í„° ê¸°ë°˜ Q&A"""
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    docs = search_vector_db(user_query, db_dir=st.secrets["CSV_VECTOR_DB_DIR"], k=3)
    context = "\n\n".join([d.page_content for d in docs])

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” CSV ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": f"ì§ˆë¬¸: {user_query}\n\nì°¸ê³ ìë£Œ:\n{context}"},
        ],
        temperature=temperature,
    )
    return response["choices"][0]["message"]["content"]


def summarize_with_ai(text: str, max_tokens: int = 500):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ìš”ì•½"""
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì„œë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ {max_tokens} í† í° ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}"},
        ],
        temperature=temperature,
    )
    return response["choices"][0]["message"]["content"]


def summarize_long_csv(csv_text: str, chunk_size: int = 2000, max_tokens: int = 500):
    """
    ê¸´ CSV í…ìŠ¤íŠ¸ë¥¼ chunk_size ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ë¶€ë¶„ ìš”ì•½ â†’ ìµœì¢… ì¢…í•© ìš”ì•½
    """
    chunks = []
    text_lines = csv_text.splitlines()

    # ğŸ”¹ CSV í…ìŠ¤íŠ¸ë¥¼ ì¼ì • ë¼ì¸ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
    for i in range(0, len(text_lines), chunk_size):
        chunk = "\n".join(text_lines[i : i + chunk_size])
        chunks.append(chunk)

    part_summaries = []
    for idx, chunk in enumerate(chunks):
        try:
            part_summary = summarize_with_ai(chunk, max_tokens=max_tokens)
            part_summaries.append(f"â–¶ï¸ Part {idx+1} ìš”ì•½:\n{part_summary}")
        except Exception as e:
            part_summaries.append(f"âš ï¸ Part {idx+1} ìš”ì•½ ì‹¤íŒ¨: {e}")

    # ğŸ”¹ ë¶€ë¶„ ìš”ì•½ë“¤ì„ ì¢…í•© ìš”ì•½
    combined_text = "\n\n".join(part_summaries)
    final_summary = summarize_with_ai(combined_text, max_tokens=max_tokens)

    return final_summary, part_summaries

def summarize_by_keywords(text: str, keywords: list[str], max_tokens: int = 700):
    """
    ì „ì²´ ë¬¸ì„œë¥¼ ì½ê³  ì£¼ì–´ì§„ í‚¤ì›Œë“œë³„ë¡œ ì •ë¦¬/ë‚˜ì—´í•˜ëŠ” í•¨ìˆ˜.
    """
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    keyword_str = ", ".join(keywords)

    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ, í‚¤ì›Œë“œ({keyword_str})ë³„ë¡œ ë‚´ìš©ì„ ì •ë¦¬í•´ì¤˜.
    ê° í‚¤ì›Œë“œë§ˆë‹¤ ê´€ë ¨ëœ ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ì—†ìœ¼ë©´ 'ê´€ë ¨ ì—†ìŒ'ì´ë¼ê³  í‘œì‹œí•´ì¤˜.

    í…ìŠ¤íŠ¸:
    {text}
    """

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì„œ ìš”ì•½ê³¼ ë¶„ë¥˜ ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
    )
    return response["choices"][0]["message"]["content"]

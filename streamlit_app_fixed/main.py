import streamlit as st
import os
import pandas as pd
from io import StringIO

from core.database import load_csv_files
from core.ai_engine import generate_ai_response, summarize_with_ai, clean_text_with_ai
from core.parsing import parse_and_store_documents

st.set_page_config(page_title="Suri Q&AI", layout="wide")
st.title("ğŸ“Š Suri Q&AI")

# --- 1. ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ + íŒŒì‹± ---
st.header("ğŸ“‘ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ ë° íŒŒì‹±")

uploaded_files = st.file_uploader(
    "txt/md íŒŒì¼ ì—…ë¡œë“œ", 
    type=["txt", "md"], 
    accept_multiple_files=True
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        file_content = uploaded_file.read().decode("utf-8")
        st.subheader(f"ğŸ“„ {uploaded_file.name}")
        st.text_area("íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", file_content[:1000], height=200)

        if st.button(f"ì´ ë¬¸ì„œ íŒŒì‹±í•˜ê¸°: {uploaded_file.name}"):
            save_path = os.path.join("data/raw_docs", uploaded_file.name)
            os.makedirs("data/raw_docs", exist_ok=True)
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(file_content)

            parsed_df = parse_and_store_documents(save_path)

            if parsed_df is not None and isinstance(parsed_df, pd.DataFrame) and not parsed_df.empty:
                st.success("âœ… íŒŒì‹± ì™„ë£Œ, AI êµì • ì ìš© ì¤‘...")

                # ğŸ”¹ DataFrame â†’ CSV ë¬¸ìì—´ ë³€í™˜
                raw_text = parsed_df.to_csv(index=False, encoding="utf-8-sig")

                # ğŸ”¹ AI êµì •
                cleaned_text = clean_text_with_ai(raw_text)

                # ğŸ”¹ êµì • ê²°ê³¼ë¥¼ ë‹¤ì‹œ DataFrameìœ¼ë¡œ ë³€í™˜
                cleaned_df = pd.read_csv(StringIO(cleaned_text))

                st.success("âœ… AI êµì • ì™„ë£Œ! ì•„ë˜ì—ì„œ ì§ì ‘ ìˆ˜ì • í›„ ì €ì¥í•˜ì„¸ìš”.")
                edited_df = st.data_editor(cleaned_df, num_rows="dynamic", width="stretch")

                if st.button(f"{uploaded_file.name} ì €ì¥", key=f"save_{uploaded_file.name}"):
                    parsed_csv = "data/parsed_docs.csv"
                    if os.path.exists(parsed_csv):
                        old_df = pd.read_csv(parsed_csv)
                        combined = pd.concat([old_df, edited_df], ignore_index=True).drop_duplicates()
                    else:
                        combined = edited_df
                    combined.to_csv(parsed_csv, index=False, encoding="utf-8-sig")
                    st.success("ğŸ“‚ parsed_docs.csv ì €ì¥ ì™„ë£Œ âœ…")
            else:
                st.warning("âš ï¸ íŒŒì‹± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 2. CSV ë°ì´í„° ê´€ë¦¬ ---
st.header("ğŸ“‚ CSV ë°ì´í„° ê´€ë¦¬")
csv_dfs = load_csv_files("data")

if not csv_dfs:
    st.info("CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì—…ë¡œë“œ/íŒŒì‹±ì„ ì§„í–‰í•˜ì„¸ìš”.")
else:
    for name, df in csv_dfs.items():
        st.subheader(f"ğŸ“‘ {name}.csv")
        edited_df = st.data_editor(df, num_rows="dynamic", width="stretch")
        if st.button(f"{name}.csv ì €ì¥", key=f"save_{name}"):
            edited_df.to_csv(f"data/{name}.csv", index=False, encoding="utf-8-sig")
            st.success(f"{name}.csv ì €ì¥ ì™„ë£Œ âœ…")

# --- 3. AI ìƒë‹´ (ì±„íŒ…ì°½) ---
st.header("ğŸ’¬ AI ìƒë‹´")

query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_query")
if st.button("AI ì‘ë‹µ ìƒì„±"):
    if query.strip():
        answer = generate_ai_response(query)
        st.markdown(answer)
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

# --- 4. CSV ì „ì²´ ìš”ì•½ ---
st.header("ğŸ“ CSV ìš”ì•½")
if st.button("CSV ì „ì²´ ìš”ì•½"):
    if not csv_dfs:
        st.warning("CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        try:
            combined_df = pd.concat(list(csv_dfs.values()), ignore_index=True)
        except ValueError as exc:
            st.error(f"CSV ë°ì´í„°ë¥¼ ê²°í•©í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            combined_df = None

        if combined_df is not None:
            # ğŸ”¹ DataFrame â†’ CSV ë¬¸ìì—´ ë³€í™˜ í›„ ìš”ì•½
            csv_text = combined_df.to_csv(index=False)
            summary = summarize_with_ai(csv_text)

            st.text_area("ìš”ì•½ ê²°ê³¼", summary, height=300)

            if st.button("ìš”ì•½ ê²°ê³¼ ì €ì¥"):
                save_path = "data/summary.csv"
                pd.DataFrame([{"summary": summary}]).to_csv(save_path, index=False, encoding="utf-8-sig")
                st.success("ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ âœ…")

# --- 5. í‚¤ì›Œë“œë³„ ì •ë¦¬ ---
st.header("ğŸ”‘ í‚¤ì›Œë“œë³„ ë¬¸ì„œ ì •ë¦¬")

keywords_input = st.text_input("í‚¤ì›Œë“œë¥¼ ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¬ë¬¼, í˜¼ì¸, ì§ì¥, ê±´ê°•)")
if st.button("í‚¤ì›Œë“œë³„ ì •ë¦¬ ì‹¤í–‰"):
    if not csv_dfs:
        st.warning("CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        combined_df = pd.concat(list(csv_dfs.values()), ignore_index=True)
        csv_text = combined_df.to_csv(index=False)

        keywords = [kw.strip() for kw in keywords_input.split(",") if kw.strip()]
        if not keywords:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            summary_by_kw = summarize_by_keywords(csv_text, keywords)
            st.text_area("í‚¤ì›Œë“œë³„ ì •ë¦¬ ê²°ê³¼", summary_by_kw, height=400)


import streamlit as st
import os
import pandas as pd

from core.database import ensure_db, insert_sample_data, load_csv_files
from core.ai_engine import generate_ai_response, summarize_with_ai
from core.parsing import parse_and_store_documents

st.set_page_config(page_title="suri Q&AI", layout="wide")
st.title("ğŸ“Š suri Q&AI")

# --- 1. ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ + íŒŒì‹± ---
st.header("ğŸ“‘ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ ë° íŒŒì‹±")

uploaded_files = st.file_uploader(
    "txt/md íŒŒì¼ ì—…ë¡œë“œ", 
    type=["txt", "md"], 
    accept_multiple_files=True
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        file_content = uploaded_file.read().decode("utf-8")
        st.subheader(f"ğŸ“„ {uploaded_file.name}")
        st.text_area("íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", file_content[:1000], height=200)

        if st.button(f"ì´ ë¬¸ì„œ íŒŒì‹±í•˜ê¸°: {uploaded_file.name}"):
            # ì €ì¥
            save_path = os.path.join("data/raw_docs", uploaded_file.name)
            os.makedirs("data/raw_docs", exist_ok=True)
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(file_content)

            # íŒŒì‹± ì‹¤í–‰
            parsed_df = parse_and_store_documents(save_path)

            if parsed_df is not None and isinstance(parsed_df, pd.DataFrame) and not parsed_df.empty:
                st.success("âœ… íŒŒì‹± ì™„ë£Œ, ê²°ê³¼ í™•ì¸")
                st.dataframe(parsed_df, width="stretch")

                # parsed_docs.csv ëˆ„ì  ì €ì¥
                parsed_csv = "data/parsed_docs.csv"
                if os.path.exists(parsed_csv):
                    old_df = pd.read_csv(parsed_csv)
                    combined = pd.concat([old_df, parsed_df], ignore_index=True).drop_duplicates()
                else:
                    combined = parsed_df
                combined.to_csv(parsed_csv, index=False, encoding="utf-8-sig")
                st.success("ğŸ“‚ parsed_docs.csv ì— ë°˜ì˜ ì™„ë£Œ")
            else:
                st.warning(âš ï¸ íŒŒì‹± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 2. CSV ë°ì´í„° ê´€ë¦¬ ---
st.header("ğŸ“‚ CSV ë°ì´í„° ê´€ë¦¬")
csv_dfs = load_csv_files("data")

if not csv_dfs:
    st.info("CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì—…ë¡œë“œ/íŒŒì‹±ì„ ì§„í–‰í•˜ì„¸ìš”.")
else:
    for name, df in csv_dfs.items():
        st.subheader(f"ğŸ“‘ {name}.csv")
        edited_df = st.data_editor(df, num_rows="dynamic", width="stretch")
        if st.button(f"{name}.csv ì €ì¥", key=f"save_{name}"):
            edited_df.to_csv(f"data/{name}.csv", index=False, encoding="utf-8-sig")
            st.success(f"{name}.csv ì €ì¥ ì™„ë£Œ âœ…")

# --- 3. AI ìƒë‹´ (ì±„íŒ…ì°½) ---
st.header("ğŸ’¬ AI ìƒë‹´")

query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_query")
if st.button("AI ì‘ë‹µ ìƒì„±"):
    if query.strip():
        answer = generate_ai_response(query)
        st.markdown(answer)
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

# --- CSV ì „ì²´ ìš”ì•½ ---
st.header("ğŸ“ CSV ìš”ì•½")
if st.button("CSV ì „ì²´ ìš”ì•½"):
    if not csv_dfs:
        st.warning("CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        combined_text = "\n".join([df.to_string() for df in csv_dfs.values()])
        summary = summarize_with_ai(combined_text)
        st.text_area("ìš”ì•½ ê²°ê³¼", summary, height=300)

        if st.button("ìš”ì•½ ê²°ê³¼ ì €ì¥"):
            save_path = "data/summary.csv"
            pd.DataFrame([{"summary": summary}]).to_csv(save_path, index=False, encoding="utf-8-sig")
            st.success("ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ âœ…")

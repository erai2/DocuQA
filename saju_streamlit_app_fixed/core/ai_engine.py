import os
import openai
from core.vector_engine import search_vector_db
from core.settings_manager import load_settings

openai.api_key = os.getenv("OPENAI_API_KEY")

def generate_ai_response(user_query, db_name="default_db"):
    settings = load_settings()
    model = settings.get("model", "gpt-4o-mini")
    temperature = float(settings.get("temperature", 0.3))

    docs = search_vector_db(user_query, db_name=db_name, k=3)
    context = "\n\n".join([f"[ì¶œì²˜:{d.metadata.get('source')}] {d.page_content}" for d in docs])

    prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ì£¼ëª…ë¦¬ ì „ë¬¸ê°€ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ ë°˜ë“œì‹œ ì•„ë˜ ë¬¸ì„œ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì„¸ìš”.

    === ì»¨í…ìŠ¤íŠ¸ ===
    {context}

    === ì§ˆë¬¸ ===
    {user_query}

    ë‹µë³€ì€ ì¹œì ˆí•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    """

    completion = openai.ChatCompletion.create(
        model=model,
        temperature=temperature,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì£¼ëª…ë¦¬ ì „ë¬¸ê°€ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ]
    )

    answer = completion.choices[0].message["content"]
    if docs:
        sources = ", ".join(set([d.metadata.get("source", "unknown") for d in docs]))
        answer += f"\n\nğŸ“Œ ì°¸ê³ ìë£Œ: {sources}"

    return answer

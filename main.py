import streamlit as st
from core.chat_manager import get_chat, add_message, clear_chat, export_chat, list_saved_chats, import_chat
from core.file_manager import save_uploaded_file, list_files, remove_file, load_all_documents
from core.vector_engine import build_vector_db_from_documents
from core.ai_engine import generate_ai_response
from core.settings_manager import load_settings, save_settings, reset_settings

st.set_page_config(page_title="ì‚¬ì£¼ëª…ë¦¬ AI ìƒë‹´ì‚¬", layout="wide")

# --- Sidebar: íŒŒì¼ ì—…ë¡œë“œ ---
st.sidebar.subheader("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ë¬¸ì„œ ì—…ë¡œë“œ", type=["txt", "md", "pdf"])
if uploaded_file is not None:
    save_uploaded_file(uploaded_file)
    st.sidebar.success(f"{uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ")

# íŒŒì¼ ëª©ë¡ í‘œì‹œ
for f in list_files():
    col1, col2 = st.sidebar.columns([3,1])
    col1.write(f)
    if col2.button("âŒ", key=f):
        remove_file(f)

# DB ì¬êµ¬ì¶• ë²„íŠ¼
if st.sidebar.button("DB ì¬êµ¬ì¶•"):
    docs = load_all_documents()
    if docs:
        build_vector_db_from_documents(docs, db_name="default_db")
        st.sidebar.success("âœ… ë²¡í„°DB ì¬êµ¬ì¶• ì™„ë£Œ")
    else:
        st.sidebar.warning("ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- Sidebar: ëŒ€í™” ê´€ë¦¬ ---
st.sidebar.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
if st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”"):
    clear_chat()
    st.sidebar.success("ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™” ì™„ë£Œ")

if st.sidebar.button("ëŒ€í™” ì €ì¥"):
    filepath = export_chat()
    st.sidebar.success(f"ëŒ€í™” ì €ì¥ë¨: {filepath}")

saved_chats = list_saved_chats()
if saved_chats:
    selected_chat = st.sidebar.selectbox("ì €ì¥ëœ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°", saved_chats)
    if st.sidebar.button("ë¶ˆëŸ¬ì˜¤ê¸°"):
        if import_chat(selected_chat):
            st.sidebar.success(f"{selected_chat} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ")

# --- Sidebar: ì„¤ì • ---
st.sidebar.subheader("âš™ï¸ ì„¤ì •")
settings = load_settings()
model = st.sidebar.selectbox(
    "GPT ëª¨ë¸",
    ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
    index=["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"].index(settings.get("model", "gpt-4o-mini"))
)
temperature = st.sidebar.slider("ì°½ì˜ì„± (Temperature)", 0.0, 1.0, float(settings.get("temperature", 0.3)), 0.1)
max_tokens = st.sidebar.number_input("ìµœëŒ€ í† í° ìˆ˜", min_value=256, max_value=4096, value=int(settings.get("max_tokens", 1000)))
vector_weight = st.sidebar.slider("ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜", 0.0, 1.0, float(settings.get("vector_weight", 0.6)), 0.1)
keyword_weight = 1 - vector_weight

if st.sidebar.button("ì„¤ì • ì €ì¥"):
    save_settings({
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "vector_weight": vector_weight,
        "keyword_weight": keyword_weight
    })
    st.sidebar.success("ì„¤ì • ì €ì¥ ì™„ë£Œ âœ…")

if st.sidebar.button("ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"):
    reset_settings()
    st.sidebar.success("ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µì›ë¨")

# --- Tabs ---
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ AI ìƒë‹´", "ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ", "âš™ï¸ ì‹œìŠ¤í…œ ì„±ëŠ¥"])

with tab1:
    st.header("AI ìƒë‹´")
    for msg in get_chat():
        st.chat_message(msg["role"]).write(msg["content"])
    if user_q := st.chat_input("ì‚¬ì£¼ëª…ë¦¬ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        add_message("user", user_q)
        answer = generate_ai_response(user_q)
        add_message("assistant", answer)
        st.experimental_rerun()

with tab2:
    st.header("ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.metric("ì´ ëŒ€í™” ìˆ˜", len(get_chat()))
    st.progress(0.9, text="ëŒ€ìš´ ê´€ë ¨ ì§ˆë¬¸ ì„±ê³µë¥  90%")
    st.progress(0.85, text="ì‹­ì‹  ì§ˆë¬¸ ì„±ê³µë¥  85%")

with tab3:
    st.header("ì‹œìŠ¤í…œ ì„±ëŠ¥")
    st.metric("í‰ê·  ì‘ë‹µì‹œê°„", "1.2s")
    st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", "65%")
    st.metric("CPU ì‚¬ìš©ë¥ ", "40%")
